= Contents =
- [[#Linear Effects|Linear Effects]]
    - [[#Data Comparison|Data Comparison]]
        - [[#Mock Data|Mock Data]]
        - [[#Real Data|Real Data]]
    - [[#Using MSE to Predict DARM|Using MSE to Predict DARM]]
        - [[#Mock Results|Mock Data]]
        - [[#Real Results|Real Data]]
- [[#Results|Results]]
    - [[#Original bilinearRegressionReal.py Script|Original bilinearRegressionReal.py Script]]
    - [[#New NN Script|New NN Script]]
        - [[#Mock Data Results|Mock Data]]
        - [[#Loss Curves|Loss Curves]]
    - [[#Effects of Notching|Effects of Notching]]
        - [[#No Notching|No Notching]]
        - [[#Notching DARM|Notching DARM]]
        - [[#Notching DARM and Witnesses|Notching DARM and Witnesses]]
- [[#Setting up NonlinearRegression Repo|Setting up NonlinearRegression Repo]]
    - [[#Log in to a cluster node with GPU support|Log in to a cluster node with GPU support]]
    - [[#Install the repo|Installing the Repository]]
    - [[#Running Examples|Running Examples]]
        - [[#Using Mock Data|Using Mock Data]]
        - [[#Using Real Data|Using Real Data]]
    - [[#Command Line Flags|Command Line Flags]]
    - [[#Building the Webpages|Building the Webpages]]


= Linear Effects =
In an effort to understand the results that we see with the real data
and the disparity in performance relative to the mock data, I decided to
look first at more simple, linear correlations between the channels and
DARM. The results, _I think_ are a clear presentation showing why this
noise cancellation is a difficult task and demonstrates, at least to some
degree, what kind of subtraction we can expect to get.

== Data Comparison ==
First, I wanted to simply look at each witness channel and compare it to
DARM to see if there were common features that would allow us to "easily"
predict the DARM spectrum based on those channels. In the case of the mock
data, the answer is a definite "yes."

=== Mock Data ===
There is very clear structure here. There was obviously an attempt to bury it
in noise, but it's more than enough for the NN to figure it out.

{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/NonlinearRegression/docs/vimwiki/images/mock_data_correlation_1.png}}

{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/NonlinearRegression/docs/vimwiki/images/mock_data_correlation_3.png}}


=== Real Data ===
There is much less structure here. I would submit that it isn't clear that a
purely linear regression would do very well.

{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/noise_cancellation/images/real_data_correlation_1.png}}

{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/noise_cancellation/images/real_data_correlation_2.png}}

{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/noise_cancellation/images/real_data_correlation_3.png}}


{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/NonlinearRegression/docs/vimwiki/images/real_channel_corr_1.png}}


{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/NonlinearRegression/docs/vimwiki/images/real_channel_corr_3.png}}


== Using MSE to Predict DARM ==
I next wanted to look at how well the channels could predict DARM by doing
Wiener filtering essentially. I start with the MSE cost function

$J(w) = \frac{1}{2m}\sum_{i=1}^{N} \left( X_j^{(i)}\cdot w^j -y^{(i)}\right)^2$

and then take the gradient and set it to zero. Solving that equation for the
weights $w$ I get

$\frac{\partial }{\partial w_k} J(w) = 0 \longrightarrow w = (X^T X)^{-1} X^T y$

Since $X$ is just my "feature" matrix and $y$ is DARM, I can easily calculate
this (depending on how invertible the term in parenthesis is). I did this
first for the mock data and then the real data. I don't care about the fit
as long as it's just a scaling issue. The coherence is all about the phases
so we can always rescale a reliable witness if we need to. Here what I found

=== Mock Results ===
Barring some scaling, the fit here is fantastic up to around 20Hz. The phases
are off, but this should get resolved through scaling I think.
{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/noise_cancellation/images/Mock_data_analytical.png}}

=== Real Results ===
This actually has decent coherence (which I can reproduct with my new NN model)
but the fit is terrible even with scaling. Some nonlinear weighting (like a NN)
could be able to fix this. The point of all this isn't to provide results
for us - this doesn't take into account a nonlinear regression. It just highlihgts
the stark differences between the real and mock data. I think it might give us _some_
idea of the kind of results that we can get though.

{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/noise_cancellation/images/Real_data_analytical.png}}


= Results =
The results of the new network that I built are shown here. The results are
very similar to the current network. Maybe I'm convincing myself that I see more
than there is, but I think the new one does perform slightly better. I have not
applied any filtering whatsoever - no whitening, no notching calibration lines,
nothing. I think this is part of the reason that I get these harmonics that show
up around 36, 48 and 60Hz. Eliminating those may go a long way towards making the
training a bit smoother. The new script is really nice and clean though. It makes
more sense to me anyway. I't makes model switching much easier since it's all
flags now, including the activation parameters. We could effectively write
wrapper scripts that do brute force hyperparameterization now.

== Original bilinearRegressionReal.py Script ==
Running with 10 epochs

{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/NonlinearRegression/docs/vimwiki/images/bilinearRegressionReal.png}}


== New NN Script ==
For the new script, I played around with the activation function tuning (I
did not do any tuning of the model atchitecture yet). Depending on what I
chose to do, I could get an interesting peak around 12Hz that is visible in
the `bilinearRegressionReal.py` script

{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/NonlinearRegression/docs/wiki/images/Sharp12HzPeak.png}}

But for the most part, the results look something like the plot below.
I'm assuming that because I'm not filtering, I'm able to catch the
60Hz and 120Hz harmonics pretty strongly. It's also nice to know that
using a completely different, independent approach to the problem that
the results are so somilar. It means that we must be doing something
right.

{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/noise_cancellation/images/Validation-LSTM-RMSProp_Great_Loss_and_Fit.png}}

I think that this is pretty good and based off of the linear, analytical solution,
it's probably close to as good as we're going to get if those two things are
correlated. I don't know if that is necessarily true. Maybe we can do much better.
Perhaps we could try to delibrately add some nonlinearity to the model? For
example, I could take products of channels and compare those to DARM like I did above
and see if are any that contain "features" that we could use. Nominally, the NN should
be able to learn these things, so I don't know if it is really worth looking into all that
much.

=== Mock Data Results ===
The mock data is essentially the same as before. Again, it's nice to see consistency
between different approaches.
{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/noise_cancellation/images/Mock_prediction.png}}

=== Loss Curves ===
Not much to say other than that things look pretty good

{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/noise_cancellation/images/loss_history_comparison.png}}

Anyway, this is where things are at. I'm going to play around with some new model
architectures and see what kind of results I can get. I'm also messing around with
the normalization to see if the feature scaling makes an important difference. I'm
having Sharan make me some time series data with injections so we can verify that
we're not losing SNR after subtraction.


== Effects of Notching ==
Each of the following uses a reduced (arbitratily) channel list

=== No Notching ===
{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/noise_cancellation/images/Short_Chan_List.png}}

=== Notching DARM ===
{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/noise_cancellation/images/DARM_notch_only_Short_list.png}}

=== Notching DARM and Witnesses ===
{{https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/noise_cancellation/images/Notched_Short_chan_list.png}}


= Setting up NonlinearRegression Repo =

== Log in to a cluster node with GPU support ==
I do everything on CIT. Michael prefers to use the dev box _dgx-1_ on LHO. I don't see much
of a performance difference between the two, though the dev box probably sees less traffic
* CIT: `gsissh ldas-pcdev11.ligo.caltech.edu`
* LHO: Pick any node then do `ssg dgx-1`. You may need an account for this. You can ask Stuart Anderson about that
* LLO: `gsissh ldas-pcdev2.ligo-la.caltech.edu`

== Install the repo ==
Hopefully this part worked for you.

{{{class="prettyprint language-bash"
$ git clone git@git.ligo.org:NoiseCancellation/NonlinearRegression.git
$ cd NonlinearRegression
$ ./install.sh
}}}

This installs tensorflow (`pip show tensorflow`) with CPU support. To run on GPUs,
you should be able to just install a different tensorflow

{{{class="prettyprint language-bash"
$ source $HOME/noise_cancellation/bin/activate
$ pip uninstall tensorflow
$ pip install tensorflow-gpu
}}}

You _may_ need to export the path to the CUDA libraries in order
to use the GPUs. I can't remember if I needed to do that or not.
To set the path, do
{{{class="prettyprint language-bash"
$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cudnn-5.1/cuda/lib64
}}}

You can also install TF with GPU support directly from the website in case you want to get a
particular version. The pip install shown above gets you the same version as below
{{{class="prettyprint language-bash"
$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp27-none-linux_x86_64.whl
}}}

== Running Examples ==
Assuming that you have mock data or real data generated and have this
data in `NonlinearRegression/tensorflow/timedelay/Data`, you should be able to
run these examples out-of-the-box.

=== Using Real Data ===
{{{class="prettyprint language-bash"
$ python train_network.py -b 1000 --activation linear -e 50 -opt rmsprop --rho 0.4 -lr 0.001 --decay 0.5
}}}

=== Using Mock Data ===
{{{class="prettyprint language-bash"
$ python train_network.py -d mock -opt rmsprop -e 100
}}}


To verify that you're indeed using GPUs, you can run `top` at the same time that you're
running one of those scripts. If your CPU usage is fairly small (under $\sim100\%$) then
you're using a GPU. You can [[https://www.tensorflow.org/tutorials/using_gpu|run TF directly]] and print out what it is running on if
you wanted a more explicit output.


== Command Line Flags ==
To see all of the flags, use `-h`
{{{class="prettyprint language-bash"
$ python train_network.py -h
usage: train_network.py [-h] [--model_type MODEL_TYPE]
                        [--train_frac TRAIN_FRAC] [--datafile DATAFILE]
                        [--data_type DATA_TYPE] [--dropout DROPOUT]
                        [--recurrent_dropout RECURRENT_DROPOUT] [--loss LOSS]
                        [--activation ACTIVATION] [--optimizer OPTIMIZER]
                        [--epochs EPOCHS] [--Nlayers NLAYERS]
                        [--batch_size BATCH_SIZE] [--shuffle SHUFFLE]
                        [--verbose VERBOSE] [--tfft TFFT] [--plotDir PLOTDIR]
                        [--plotStrain PLOTSTRAIN] [--doPlots DOPLOTS]
                        [--lookback LOOKBACK] [--learning_rate LR]
                        [--decay DECAY] [--momentum MOMENTUM]
                        [--nesterov NESTEROV] [--beta_1 BETA_1]
                        [--beta_2 BETA_2] [--epsilon EPSILON] [--rho RHO]
                        [--interferometer IFO] [--save_data SAVE_DATA]
                        [--doLines DOLINES] [--chans CHANS] [--width WIDTH]
                        [--notch_freqs NOTCH_FREQS [NOTCH_FREQS ...]]

optional arguments:
  -h, --help            show this help message and exit
  --model_type MODEL_TYPE, -m MODEL_TYPE
                        pick model type to use
  --train_frac TRAIN_FRAC
                        ratio of dataset used for training
  --datafile DATAFILE   data file to read from
  --data_type DATA_TYPE, -d DATA_TYPE
                        real or mock data
  --dropout DROPOUT, -D DROPOUT
                        dropout regularization
  --recurrent_dropout RECURRENT_DROPOUT, -RD RECURRENT_DROPOUT
                        recurrent dropout used in RNN memory blocks
  --loss LOSS           loss function for neural network
  --activation ACTIVATION, -a ACTIVATION
                        activation function for neural network
  --optimizer OPTIMIZER, -opt OPTIMIZER
                        optimizing function for neural network
  --epochs EPOCHS, -e EPOCHS
                        Number of iterations of NN training
  --Nlayers NLAYERS, -l NLAYERS
                        Number of layers for the Dense network
  --batch_size BATCH_SIZE, -b BATCH_SIZE
                        number of samples to be trained at once
  --shuffle SHUFFLE, -s SHUFFLE
                        shuffle training data
  --verbose VERBOSE, -v VERBOSE
                        output verbosity
  --tfft TFFT           Use to set overlapping segments for PSD
  --plotDir PLOTDIR     directory to store plots
  --plotStrain PLOTSTRAIN
                        plot Strain data
  --doPlots DOPLOTS     enable plotting
  --lookback LOOKBACK, -lb LOOKBACK
                        timesteps to look back
  --learning_rate LR, -lr LR
                        optimizer learning rate
  --decay DECAY         optimizer learning rate decay
  --momentum MOMENTUM   optimizer momentum
  --nesterov NESTEROV   use nesterov momentum
  --beta_1 BETA_1       beta_1 params for optimizer
  --beta_2 BETA_2       beta_2 params for optimizer
  --epsilon EPSILON     optimizer param
  --rho RHO             adadelta & rmsprop optimizer params
  --interferometer IFO, -ifo IFO
                        L1 or H1
  --save_data SAVE_DATA
                        save data to mat file
  --doLines DOLINES     remove lines from raw DARM
  --chans CHANS         channel(s) to notch. Either 'darm' or 'all'
  --width WIDTH         notching bin width
  --notch_freqs NOTCH_FREQS [NOTCH_FREQS ...]
                        frequencies to notch
}}}


== Building Webpages ==
Making the webpages like the ones you saw should just be one command. Let's first run two
models that we wish to compare

{{{class="prettyprint language-bash"
$ python train_network.py -b 1000 --activation linear -e 50 -opt rmsprop --rho 0.4 -lr 0.001 --decay 0.5
$ python train_network.py --activation linear -e 10 -opt adadelta -lr 1 --rho 0.1 --decay 0.0 -m MLP
}}}

One uses LSTMs and the other uses multi-layer perceptrons. Next, specify the models to
compare in the config file here: `$HOME/noise_cancellation/configs/configs.ini`. It should look
something like this

{{{class="prettyprint language-bash"
[run]
basedir = /home/rana.adhikari/git_repositories/NonlinearRegression
models  = LSTM, MLP
}}}

You can make as many models as you want and add them here for comparison. I wouldn't add more than
three models at once otherwise the figures start getting a bit small. Now we can build the webpages

{{{class="prettyprint language-bash"
$ nlr-compare-models
Using Tensorflow backend
Using Tensorflow backend
[+] Webpages built successfully
}}}

The webpages are built in `NonllinearRegression/HTML`. Soft link this directory to your
`public_html` directory so you can view them online.

{{{class="prettyprint language-bash"
$ ln -s $HOME/git_repositories/NonlinearRegression/NonlinearRegression/HTML $HOME/public_html
}}}

If you're doing this on CIT, you should be able to see your results
[[https://ldas-jobs.ligo.caltech.edu/~rana.adhikari/|here]]

Let me know if you have any troubles. There are some docs [[https://ldas-jobs.ligo.caltech.edu/~rich.ormiston/NonlinearRegression/docs/build/html/|here]] which may help though I haven't updated them in a while so
they're probably a little dated. I'm in the process of cleaning things up so the
directory structure should be much nicer in short order. I'll keep you updated.

